"""
ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ

Langchain ê¸°ë°˜ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í™œìš© ì˜ˆì œ
- ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì„¤ì • ë° ì‹¤í–‰
- í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì„±
- ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤
- ì‹¤ì‹œê°„ ì•Œë¦¼ ë° ë¦¬í¬íŠ¸ ìƒì„±
"""

import asyncio
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional

from loguru import logger

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ import
from ..core.performance_monitor import PerformanceMonitor, MetricType, AlertLevel
from ..core.monitoring_integration import MonitoringIntegration, MonitoringConfig
from ..core.agent_system import AIAgentSystem, SystemConfig
from ..core.chain_manager import ChainManager
from ..core.chain_service import ChainService
from ..core.coordinator import AgentCoordinator

# ê¸°ë³¸ ì—ì´ì „íŠ¸ ë° ì„¤ì • import
from ..core.agent_base import AgentConfig
from ..agents.search_strategy_agent import SearchStrategyAgent
from ..agents.contact_agent import ContactAgent
from ..agents.validation_agent import ValidationAgent
from ..agents.optimizer_agent import OptimizerAgent
from ..utils.gemini_client import GeminiClient, ModelType


class MonitoringExampleRunner:
    """
    ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰ê¸°
    
    ë‹¤ì–‘í•œ ëª¨ë‹ˆí„°ë§ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        """ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰ê¸° ì´ˆê¸°í™”"""
        self.performance_monitor = None
        self.monitoring_integration = None
        self.agent_system = None
        self.chain_manager = None
        self.chain_service = None
        self.coordinator = None
        
        logger.info("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    async def setup_monitoring_system(self) -> Dict[str, Any]:
        """
        í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì •
        
        Returns:
            ì„¤ì • ê²°ê³¼
        """
        logger.info("ğŸ”§ í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì‹œì‘")
        
        try:
            # 1. AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            system_config = SystemConfig(
                name="ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ",
                version="1.0.0",
                environment="test",
                debug_mode=True,
                enable_monitoring=True
            )
            self.agent_system = AIAgentSystem(system_config)
            
            # 2. ì²´ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.chain_manager = ChainManager()
            self.chain_service = ChainService(self.chain_manager)
            
            # 3. ì›Œí¬í”Œë¡œìš° ì¡°ì •ì ì´ˆê¸°í™”
            self.coordinator = AgentCoordinator(self.agent_system)
            
            # 4. ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ ë“±ë¡
            await self._register_test_agents()
            
            # 5. ëª¨ë‹ˆí„°ë§ í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            monitoring_config = MonitoringConfig(
                enable_agent_monitoring=True,
                enable_chain_monitoring=True,
                enable_workflow_monitoring=True,
                enable_system_monitoring=True,
                agent_metrics_interval=10.0,  # í…ŒìŠ¤íŠ¸ìš© ë¹ ë¥¸ ê°„ê²©
                chain_metrics_interval=5.0,
                system_metrics_interval=15.0
            )
            
            self.monitoring_integration = MonitoringIntegration(
                agent_system=self.agent_system,
                chain_manager=self.chain_manager,
                chain_service=self.chain_service,
                coordinator=self.coordinator,
                config=monitoring_config
            )
            
            # 6. ê¸°ë³¸ ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
            self.performance_monitor = self.monitoring_integration.performance_monitor
            
            logger.info("âœ… í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
            
            return {
                "status": "success",
                "components": {
                    "agent_system": "initialized",
                    "chain_manager": "initialized", 
                    "chain_service": "initialized",
                    "coordinator": "initialized",
                    "monitoring_integration": "initialized"
                },
                "registered_agents": len(self.agent_system.agents),
                "monitoring_config": {
                    "agent_monitoring": monitoring_config.enable_agent_monitoring,
                    "chain_monitoring": monitoring_config.enable_chain_monitoring,
                    "workflow_monitoring": monitoring_config.enable_workflow_monitoring
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _register_test_agents(self):
        """í…ŒìŠ¤íŠ¸ìš© ì—ì´ì „íŠ¸ë“¤ ë“±ë¡"""
        try:
            # ê¸°ë³¸ ì—ì´ì „íŠ¸ ì„¤ì •
            base_config = AgentConfig(
                name="test_agent",
                model_type=ModelType.GEMINI_1_5_FLASH,
                temperature=0.7,
                max_tokens=1000,
                timeout=30.0,
                debug_mode=True
            )
            
            # ê²€ìƒ‰ ì „ëµ ì—ì´ì „íŠ¸
            search_config = base_config
            search_config.name = "SearchStrategyAgent"
            search_agent = SearchStrategyAgent(search_config)
            self.agent_system.register_agent("SearchStrategyAgent", search_agent)
            
            # ì—°ë½ì²˜ ì—ì´ì „íŠ¸
            contact_config = base_config
            contact_config.name = "ContactAgent"
            contact_agent = ContactAgent(contact_config)
            self.agent_system.register_agent("ContactAgent", contact_agent)
            
            # ê²€ì¦ ì—ì´ì „íŠ¸
            validation_config = base_config
            validation_config.name = "ValidationAgent"
            validation_agent = ValidationAgent(validation_config)
            self.agent_system.register_agent("ValidationAgent", validation_agent)
            
            # ìµœì í™” ì—ì´ì „íŠ¸
            optimizer_config = base_config
            optimizer_config.name = "OptimizerAgent"
            optimizer_agent = OptimizerAgent(optimizer_config)
            self.agent_system.register_agent("OptimizerAgent", optimizer_agent)
            
            logger.info(f"âœ… {len(self.agent_system.agents)}ê°œ í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ ë“±ë¡ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ ë“±ë¡ ì‹¤íŒ¨: {e}")
            raise

    async def run_basic_monitoring_example(self) -> Dict[str, Any]:
        """
        ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰
        
        Returns:
            ëª¨ë‹ˆí„°ë§ ê²°ê³¼
        """
        logger.info("ğŸ“Š ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹œì‘")
        
        if not self.performance_monitor:
            return {"error": "ì„±ëŠ¥ ëª¨ë‹ˆí„°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # 1. ëª¨ë‹ˆí„°ë§ ì‹œì‘
            await self.performance_monitor.start_monitoring()
            
            # 2. í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ê¸°ë¡
            await self._generate_test_metrics()
            
            # 3. 5ì´ˆ ëŒ€ê¸° (ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œê°„)
            await asyncio.sleep(5)
            
            # 4. ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
            report = await self.performance_monitor.get_performance_report("1hour")
            
            # 5. í˜„ì¬ ìƒíƒœ í™•ì¸
            current_status = self.performance_monitor.get_current_status()
            
            # 6. ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            await self.performance_monitor.stop_monitoring()
            
            logger.info("âœ… ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì™„ë£Œ")
            
            return {
                "status": "success",
                "monitoring_duration": "5 seconds",
                "performance_report": report,
                "current_status": current_status,
                "insights": [
                    "ê¸°ë³¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì •ìƒ ì‘ë™",
                    "í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ",
                    "ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ"
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _generate_test_metrics(self):
        """í…ŒìŠ¤íŠ¸ìš© ë©”íŠ¸ë¦­ ìƒì„±"""
        # ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_monitor.record_agent_metric(
            agent_name="SearchStrategyAgent",
            metric_name="execution_time",
            value=2.5,
            unit="seconds",
            metadata={"test": True}
        )
        
        self.performance_monitor.record_agent_metric(
            agent_name="ContactAgent",
            metric_name="success_rate",
            value=0.95,
            unit="ratio"
        )
        
        # ì²´ì¸ ì‹¤í–‰ ë©”íŠ¸ë¦­
        self.performance_monitor.record_chain_metric(
            chain_name="test_search_chain",
            execution_result={"success": True, "data": "test_result"},
            execution_time=1.8
        )
        
        self.performance_monitor.record_chain_metric(
            chain_name="test_validation_chain",
            execution_result={"success": True, "validated": True},
            execution_time=0.9
        )

    async def run_integrated_monitoring_example(self) -> Dict[str, Any]:
        """
        í†µí•© ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰
        
        Returns:
            í†µí•© ëª¨ë‹ˆí„°ë§ ê²°ê³¼
        """
        logger.info("ğŸ”— í†µí•© ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹œì‘")
        
        if not self.monitoring_integration:
            return {"error": "í†µí•© ëª¨ë‹ˆí„°ë§ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # 1. í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œì‘
            await self.monitoring_integration.start_integrated_monitoring()
            
            # 2. í…ŒìŠ¤íŠ¸ ì‘ì—… ì‹¤í–‰
            test_results = await self._run_test_workloads()
            
            # 3. 10ì´ˆ ëŒ€ê¸° (í†µí•© ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œê°„)
            await asyncio.sleep(10)
            
            # 4. í†µí•© ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
            integrated_report = await self.monitoring_integration.get_integrated_report("1hour")
            
            # 5. ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸
            monitoring_status = self.monitoring_integration.get_monitoring_status()
            
            # 6. í†µí•© ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            await self.monitoring_integration.stop_integrated_monitoring()
            
            logger.info("âœ… í†µí•© ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì™„ë£Œ")
            
            return {
                "status": "success",
                "test_workloads": test_results,
                "integrated_report": integrated_report,
                "monitoring_status": monitoring_status,
                "insights": [
                    "ì „ì²´ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ í†µí•© ëª¨ë‹ˆí„°ë§ ì„±ê³µ",
                    "ì—ì´ì „íŠ¸, ì²´ì¸, ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ ì¶”ì  ì™„ë£Œ",
                    "ì‹¤ì‹œê°„ ì„±ëŠ¥ í›… ì •ìƒ ì‘ë™ í™•ì¸"
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _run_test_workloads(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ì›Œí¬ë¡œë“œ ì‹¤í–‰"""
        results = {}
        
        try:
            # 1. ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‘ì—… í…ŒìŠ¤íŠ¸
            search_result = await self.agent_system.process_single_task(
                "SearchStrategyAgent",
                {"query": "test search", "target": "test_target"}
            )
            results["search_task"] = search_result.success
            
            # 2. ì²´ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
            if hasattr(self.chain_service, 'execute_chain'):
                chain_result = await self.chain_service.execute_chain(
                    "test_chain",
                    {"input": "test_data"}
                )
                results["chain_execution"] = True
            else:
                results["chain_execution"] = "not_available"
            
            # 3. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            batch_data = [
                {"item": "test1"},
                {"item": "test2"},
                {"item": "test3"}
            ]
            batch_results = await self.agent_system.process_batch(
                "ValidationAgent",
                batch_data,
                max_concurrent=2
            )
            results["batch_processing"] = {
                "total": len(batch_results),
                "successful": sum(1 for r in batch_results if r.success)
            }
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì›Œí¬ë¡œë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def run_performance_analysis_example(self) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ ë¶„ì„ ì˜ˆì œ ì‹¤í–‰
        
        Returns:
            ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼
        """
        logger.info("ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ì˜ˆì œ ì‹œì‘")
        
        if not self.monitoring_integration:
            return {"error": "í†µí•© ëª¨ë‹ˆí„°ë§ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # 1. ëª¨ë‹ˆí„°ë§ ì‹œì‘
            await self.monitoring_integration.start_integrated_monitoring()
            
            # 2. ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
            load_test_results = await self._run_load_test_scenario()
            
            # 3. 15ì´ˆ ëŒ€ê¸° (ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘)
            await asyncio.sleep(15)
            
            # 4. ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰
            await self.monitoring_integration.optimize_integrated_performance()
            
            # 5. ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
            final_report = await self.monitoring_integration.get_integrated_report("1hour")
            
            # 6. ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            await self.monitoring_integration.stop_integrated_monitoring()
            
            logger.info("âœ… ì„±ëŠ¥ ë¶„ì„ ì˜ˆì œ ì™„ë£Œ")
            
            return {
                "status": "success",
                "load_test_results": load_test_results,
                "performance_analysis": final_report,
                "optimization_applied": True,
                "insights": [
                    "ë¶€í•˜ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì„±ëŠ¥ ë³‘ëª©ì  ì‹ë³„",
                    "ìë™ ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰ ì™„ë£Œ",
                    "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„ ì™„ë£Œ"
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ ë¶„ì„ ì˜ˆì œ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _run_load_test_scenario(self) -> Dict[str, Any]:
        """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        logger.info("ğŸš€ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘")
        
        results = {
            "total_tasks": 0,
            "successful_tasks": 0,
            "failed_tasks": 0,
            "average_response_time": 0.0,
            "peak_memory_usage": 0.0
        }
        
        try:
            # ë™ì‹œ ì‘ì—… ì‹¤í–‰
            tasks = []
            start_time = time.time()
            
            # 10ê°œì˜ ë™ì‹œ ì—ì´ì „íŠ¸ ì‘ì—…
            for i in range(10):
                task = self.agent_system.process_single_task(
                    "SearchStrategyAgent",
                    {"query": f"load_test_{i}", "item_id": i}
                )
                tasks.append(task)
            
            # 5ê°œì˜ ë™ì‹œ ë°°ì¹˜ ì‘ì—…
            for i in range(5):
                batch_data = [{"batch_item": j} for j in range(3)]
                task = self.agent_system.process_batch(
                    "ContactAgent",
                    batch_data,
                    max_concurrent=2
                )
                tasks.append(task)
            
            # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            task_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ë¶„ì„
            total_time = time.time() - start_time
            successful_count = 0
            failed_count = 0
            
            for result in task_results:
                if isinstance(result, Exception):
                    failed_count += 1
                else:
                    if hasattr(result, 'success'):
                        if result.success:
                            successful_count += 1
                        else:
                            failed_count += 1
                    elif isinstance(result, list):
                        # ë°°ì¹˜ ê²°ê³¼
                        for batch_result in result:
                            if batch_result.success:
                                successful_count += 1
                            else:
                                failed_count += 1
            
            results.update({
                "total_tasks": len(task_results),
                "successful_tasks": successful_count,
                "failed_tasks": failed_count,
                "average_response_time": total_time / len(task_results),
                "total_execution_time": total_time
            })
            
            logger.info(f"âœ… ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {successful_count}/{len(task_results)} ì„±ê³µ")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def run_alert_monitoring_example(self) -> Dict[str, Any]:
        """
        ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰
        
        Returns:
            ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ê²°ê³¼
        """
        logger.info("ğŸš¨ ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹œì‘")
        
        if not self.performance_monitor:
            return {"error": "ì„±ëŠ¥ ëª¨ë‹ˆí„°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # 1. ëª¨ë‹ˆí„°ë§ ì‹œì‘
            await self.performance_monitor.start_monitoring()
            
            # 2. ì˜ë„ì ìœ¼ë¡œ ì„ê³„ê°’ ì´ˆê³¼ ìƒí™© ìƒì„±
            await self._simulate_performance_issues()
            
            # 3. 5ì´ˆ ëŒ€ê¸° (ì•Œë¦¼ ìƒì„± ì‹œê°„)
            await asyncio.sleep(5)
            
            # 4. ìƒì„±ëœ ì•Œë¦¼ í™•ì¸
            current_status = self.performance_monitor.get_current_status()
            
            # 5. ì„±ëŠ¥ ë¦¬í¬íŠ¸ì—ì„œ ì•Œë¦¼ ìš”ì•½ í™•ì¸
            report = await self.performance_monitor.get_performance_report("1hour")
            
            # 6. ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            await self.performance_monitor.stop_monitoring()
            
            logger.info("âœ… ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì™„ë£Œ")
            
            return {
                "status": "success",
                "current_status": current_status,
                "alerts_summary": report.get("alerts_summary", {}),
                "simulated_issues": [
                    "CPU ì‚¬ìš©ë¥  ì„ê³„ê°’ ì´ˆê³¼ ì‹œë®¬ë ˆì´ì…˜",
                    "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê²½ê³  ìˆ˜ì¤€ ì‹œë®¬ë ˆì´ì…˜",
                    "ì—ì´ì „íŠ¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ ì‹œë®¬ë ˆì´ì…˜"
                ],
                "insights": [
                    "ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ í™•ì¸",
                    "ì„ê³„ê°’ ê¸°ë°˜ ìë™ ì•Œë¦¼ ìƒì„± ì„±ê³µ",
                    "ì„±ëŠ¥ ì´ìŠˆ ê°ì§€ ë° ì¶”ì  ê¸°ëŠ¥ ê²€ì¦"
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _simulate_performance_issues(self):
        """ì„±ëŠ¥ ì´ìŠˆ ì‹œë®¬ë ˆì´ì…˜"""
        # ë†’ì€ CPU ì‚¬ìš©ë¥  ì‹œë®¬ë ˆì´ì…˜
        self.performance_monitor.record_agent_metric(
            agent_name="system",
            metric_name="cpu_usage",
            value=87.5,  # ì„ê³„ê°’ ì´ˆê³¼
            unit="%",
            metadata={"simulated": True}
        )
        
        # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì‹œë®¬ë ˆì´ì…˜  
        self.performance_monitor.record_agent_metric(
            agent_name="system",
            metric_name="memory_usage",
            value=78.3,  # ê²½ê³  ìˆ˜ì¤€
            unit="%",
            metadata={"simulated": True}
        )
        
        # ê¸´ ì‘ë‹µ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        self.performance_monitor.record_agent_metric(
            agent_name="SlowAgent",
            metric_name="execution_time",
            value=25.7,  # ì„ê³„ê°’ ì´ˆê³¼
            unit="seconds",
            metadata={"simulated": True, "timeout_risk": True}
        )

    async def run_comprehensive_monitoring_demo(self) -> Dict[str, Any]:
        """
        ì¢…í•© ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì‹¤í–‰
        
        Returns:
            ì¢…í•© ë°ëª¨ ê²°ê³¼
        """
        logger.info("ğŸ¯ ì¢…í•© ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì‹œì‘")
        
        demo_results = {
            "demo_start_time": datetime.now().isoformat(),
            "executed_scenarios": [],
            "overall_status": "pending"
        }
        
        try:
            # 1. ì‹œìŠ¤í…œ ì„¤ì •
            setup_result = await self.setup_monitoring_system()
            demo_results["system_setup"] = setup_result
            
            if setup_result["status"] != "success":
                demo_results["overall_status"] = "setup_failed"
                return demo_results
            
            # 2. ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ
            logger.info("ğŸ“Š 1ë‹¨ê³„: ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰")
            basic_result = await self.run_basic_monitoring_example()
            demo_results["basic_monitoring"] = basic_result
            demo_results["executed_scenarios"].append("basic_monitoring")
            
            # 3. í†µí•© ëª¨ë‹ˆí„°ë§ ì˜ˆì œ
            logger.info("ğŸ”— 2ë‹¨ê³„: í†µí•© ëª¨ë‹ˆí„°ë§ ì‹¤í–‰")
            integrated_result = await self.run_integrated_monitoring_example()
            demo_results["integrated_monitoring"] = integrated_result
            demo_results["executed_scenarios"].append("integrated_monitoring")
            
            # 4. ì„±ëŠ¥ ë¶„ì„ ì˜ˆì œ
            logger.info("ğŸ“ˆ 3ë‹¨ê³„: ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰")
            analysis_result = await self.run_performance_analysis_example()
            demo_results["performance_analysis"] = analysis_result
            demo_results["executed_scenarios"].append("performance_analysis")
            
            # 5. ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ
            logger.info("ğŸš¨ 4ë‹¨ê³„: ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰")
            alert_result = await self.run_alert_monitoring_example()
            demo_results["alert_monitoring"] = alert_result
            demo_results["executed_scenarios"].append("alert_monitoring")
            
            # 6. ìµœì¢… ìƒíƒœ í™•ì¸
            if all([
                basic_result.get("status") == "success",
                integrated_result.get("status") == "success",
                analysis_result.get("status") == "success",
                alert_result.get("status") == "success"
            ]):
                demo_results["overall_status"] = "success"
            else:
                demo_results["overall_status"] = "partial_success"
            
            demo_results["demo_end_time"] = datetime.now().isoformat()
            demo_results["total_scenarios"] = len(demo_results["executed_scenarios"])
            
            # 7. ì¢…í•© ì¸ì‚¬ì´íŠ¸
            demo_results["comprehensive_insights"] = [
                "Langchain ê¸°ë°˜ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì™„ì „ êµ¬í˜„",
                "ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™",
                "í†µí•© ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì „ì²´ ì‹œìŠ¤í…œ ê°€ì‹œì„± í™•ë³´",
                "ìë™í™”ëœ ì„±ëŠ¥ ìµœì í™” ë° ì•Œë¦¼ ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ",
                "í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ"
            ]
            
            logger.info("ğŸ‰ ì¢…í•© ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì™„ë£Œ")
            
            return demo_results
            
        except Exception as e:
            logger.error(f"âŒ ì¢…í•© ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì‹¤íŒ¨: {e}")
            demo_results["overall_status"] = "failed"
            demo_results["error"] = str(e)
            return demo_results


# ì‹¤í–‰ í•¨ìˆ˜ë“¤
async def run_monitoring_examples():
    """ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰"""
    runner = MonitoringExampleRunner()
    
    logger.info("ğŸš€ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì˜ˆì œ ì‹œì‘")
    
    # ì¢…í•© ë°ëª¨ ì‹¤í–‰
    results = await runner.run_comprehensive_monitoring_demo()
    
    logger.info("ğŸ“‹ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰ ê²°ê³¼:")
    logger.info(f"ì „ì²´ ìƒíƒœ: {results['overall_status']}")
    logger.info(f"ì‹¤í–‰ëœ ì‹œë‚˜ë¦¬ì˜¤: {results['executed_scenarios']}")
    logger.info(f"ì´ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜: {results.get('total_scenarios', 0)}")
    
    return results


def print_monitoring_report(results: Dict[str, Any]):
    """ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹¤í–‰ ë¦¬í¬íŠ¸")
    print("="*80)
    
    print(f"\nğŸ¯ ì „ì²´ ì‹¤í–‰ ìƒíƒœ: {results.get('overall_status', 'unknown').upper()}")
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {results.get('demo_start_time', 'N/A')} ~ {results.get('demo_end_time', 'N/A')}")
    print(f"ğŸ”¢ ì‹¤í–‰ëœ ì‹œë‚˜ë¦¬ì˜¤: {results.get('total_scenarios', 0)}ê°œ")
    
    if 'executed_scenarios' in results:
        print(f"\nğŸ“‹ ì‹¤í–‰ ì‹œë‚˜ë¦¬ì˜¤ ëª©ë¡:")
        for i, scenario in enumerate(results['executed_scenarios'], 1):
            print(f"  {i}. {scenario}")
    
    if 'comprehensive_insights' in results:
        print(f"\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
        for i, insight in enumerate(results['comprehensive_insights'], 1):
            print(f"  {i}. {insight}")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    async def main():
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        try:
            # ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì‹¤í–‰
            results = await run_monitoring_examples()
            
            # ê²°ê³¼ ì¶œë ¥
            print_monitoring_report(results)
            
            # JSON í˜•íƒœë¡œë„ ì¶œë ¥ (ì„ íƒì‚¬í•­)
            if results.get('overall_status') == 'success':
                print(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ (JSON):")
                print(json.dumps(results, indent=2, ensure_ascii=False))
            
        except Exception as e:
            logger.error(f"âŒ ë©”ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            print(f"\nğŸ’¥ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    asyncio.run(main()) 