"""
â˜ï¸ GCP e2-small í™˜ê²½ ìµœì í™” ì‹œìŠ¤í…œ

Google Cloud Platform e2-small ì¸ìŠ¤í„´ìŠ¤(2 vCPU, 4GB RAM) í™˜ê²½ì— íŠ¹í™”ëœ ìµœì í™” ì‹œìŠ¤í…œ
- ë¦¬ì†ŒìŠ¤ ì œì•½ ì¡°ê±´ ê´€ë¦¬
- ë¹„ìš© íš¨ìœ¨ì„± ìµœì í™”
- ì„±ëŠ¥ íŠœë‹ ë° ëª¨ë‹ˆí„°ë§
- ìë™ ìŠ¤ì¼€ì¼ë§ ê¶Œì¥ì‚¬í•­
- AI ì›Œí¬ë¡œë“œ ìµœì í™”
"""

import asyncio
import time
import json
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from collections import defaultdict, deque

from loguru import logger

from .performance_monitor import PerformanceMonitor, MetricType, AlertLevel
from .monitoring_integration import MonitoringIntegration
from ..utils.gemini_client import GeminiClient
from ..utils.rate_limiter import RateLimiter
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain


class GCPInstanceType(Enum):
    """GCP ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…"""
    E2_MICRO = "e2-micro"           # 1 vCPU, 1GB RAM
    E2_SMALL = "e2-small"           # 2 vCPU, 2GB RAM
    E2_MEDIUM = "e2-medium"         # 2 vCPU, 4GB RAM
    E2_STANDARD_2 = "e2-standard-2" # 2 vCPU, 8GB RAM
    E2_STANDARD_4 = "e2-standard-4" # 4 vCPU, 16GB RAM


class OptimizationLevel(Enum):
    """ìµœì í™” ìˆ˜ì¤€"""
    CONSERVATIVE = "conservative"    # ë³´ìˆ˜ì  ìµœì í™”
    BALANCED = "balanced"           # ê· í˜• ì¡íŒ ìµœì í™”
    AGGRESSIVE = "aggressive"       # ì ê·¹ì  ìµœì í™”
    MAXIMUM = "maximum"             # ìµœëŒ€ ìµœì í™”


class ResourceConstraint(Enum):
    """ë¦¬ì†ŒìŠ¤ ì œì•½ ì¡°ê±´"""
    CPU_BOUND = "cpu_bound"         # CPU ì œì•½
    MEMORY_BOUND = "memory_bound"   # ë©”ëª¨ë¦¬ ì œì•½
    NETWORK_BOUND = "network_bound" # ë„¤íŠ¸ì›Œí¬ ì œì•½
    DISK_BOUND = "disk_bound"       # ë””ìŠ¤í¬ ì œì•½
    API_BOUND = "api_bound"         # API í• ë‹¹ëŸ‰ ì œì•½


@dataclass
class GCPResourceSpec:
    """GCP ë¦¬ì†ŒìŠ¤ ì‚¬ì–‘"""
    instance_type: GCPInstanceType
    vcpu_count: int
    memory_gb: float
    network_tier: str = "standard"
    disk_type: str = "pd-balanced"
    disk_size_gb: int = 10
    
    # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ (OS ì˜¤ë²„í—¤ë“œ ê³ ë ¤)
    @property
    def usable_memory_gb(self) -> float:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (OS ì˜¤ë²„í—¤ë“œ ì œì™¸)"""
        return self.memory_gb * 0.85  # 15% OS ì˜¤ë²„í—¤ë“œ
    
    @property
    def usable_vcpu_count(self) -> float:
        """ì‚¬ìš© ê°€ëŠ¥í•œ vCPU (ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤ ì œì™¸)"""
        return self.vcpu_count * 0.9  # 10% ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤


@dataclass
class GCPOptimizationRecommendation:
    """GCP ìµœì í™” ê¶Œì¥ì‚¬í•­"""
    id: str
    category: str                           # resource/cost/performance/scaling
    priority: int                           # 1(ë†’ìŒ) ~ 5(ë‚®ìŒ)
    title: str
    description: str
    expected_improvement: Dict[str, float]  # {"cpu": 15.0, "memory": 20.0, "cost": 25.0}
    implementation_steps: List[str]
    estimated_effort: str                   # low/medium/high
    estimated_time: str
    cost_impact: str                        # positive/negative/neutral
    risk_level: str                         # low/medium/high
    
    # GCP íŠ¹í™” ì •ë³´
    gcp_services: List[str] = field(default_factory=list)
    billing_impact: Optional[str] = None
    monitoring_metrics: List[str] = field(default_factory=list)


@dataclass
class GCPWorkloadProfile:
    """GCP ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼"""
    workload_type: str                      # ai_inference/web_crawling/data_processing
    peak_cpu_usage: float
    peak_memory_usage: float
    average_cpu_usage: float
    average_memory_usage: float
    network_throughput_mbps: float
    disk_io_iops: float
    api_requests_per_minute: float
    burst_capability_required: bool = False
    
    # ì‹œê°„ëŒ€ë³„ íŒ¨í„´
    hourly_patterns: Dict[str, float] = field(default_factory=dict)
    daily_patterns: Dict[str, float] = field(default_factory=dict)


class GCPOptimizer:
    """
    â˜ï¸ GCP e2-small í™˜ê²½ ìµœì í™” ì‹œìŠ¤í…œ
    
    ê¸°ëŠ¥:
    - GCP ë¦¬ì†ŒìŠ¤ ì‚¬ì–‘ ë¶„ì„ ë° ìµœì í™”
    - ë¹„ìš© íš¨ìœ¨ì„± ê°œì„ 
    - ì„±ëŠ¥ ë³‘ëª©ì  í•´ê²°
    - ìë™ ìŠ¤ì¼€ì¼ë§ ê¶Œì¥ì‚¬í•­
    - AI ì›Œí¬ë¡œë“œ ìµœì í™”
    """
    
    def __init__(
        self,
        target_instance: GCPInstanceType = GCPInstanceType.E2_SMALL,
        optimization_level: OptimizationLevel = OptimizationLevel.BALANCED,
        performance_monitor: Optional[PerformanceMonitor] = None
    ):
        """
        GCP ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            target_instance: ëŒ€ìƒ GCP ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…
            optimization_level: ìµœì í™” ìˆ˜ì¤€
            performance_monitor: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
        """
        self.target_instance = target_instance
        self.optimization_level = optimization_level
        self.performance_monitor = performance_monitor
        
        # GCP ë¦¬ì†ŒìŠ¤ ì‚¬ì–‘ ì •ì˜
        self.resource_specs = {
            GCPInstanceType.E2_MICRO: GCPResourceSpec(GCPInstanceType.E2_MICRO, 1, 1.0),
            GCPInstanceType.E2_SMALL: GCPResourceSpec(GCPInstanceType.E2_SMALL, 2, 2.0),
            GCPInstanceType.E2_MEDIUM: GCPResourceSpec(GCPInstanceType.E2_MEDIUM, 2, 4.0),
            GCPInstanceType.E2_STANDARD_2: GCPResourceSpec(GCPInstanceType.E2_STANDARD_2, 2, 8.0),
            GCPInstanceType.E2_STANDARD_4: GCPResourceSpec(GCPInstanceType.E2_STANDARD_4, 4, 16.0)
        }
        
        self.current_spec = self.resource_specs[target_instance]
        
        # ìµœì í™” íˆìŠ¤í† ë¦¬
        self.optimization_history: deque = deque(maxlen=100)
        self.recommendation_cache: Dict[str, GCPOptimizationRecommendation] = {}
        
        # AI í´ë¼ì´ì–¸íŠ¸
        self.gemini_client = GeminiClient()
        
        # ìµœì í™” ì„ê³„ê°’ ì„¤ì •
        self._setup_optimization_thresholds()
        
        # Langchain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self._setup_prompts()
        
        logger.info(f"â˜ï¸ GCP ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”: {target_instance.value} ({optimization_level.value})")

    def _setup_optimization_thresholds(self):
        """ìµœì í™” ì„ê³„ê°’ ì„¤ì •"""
        base_thresholds = {
            "cpu_warning": 65.0,
            "cpu_critical": 80.0,
            "memory_warning": 70.0,
            "memory_critical": 85.0,
            "cost_efficiency_min": 0.7,
            "performance_score_min": 0.8
        }
        
        # ìµœì í™” ìˆ˜ì¤€ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •
        if self.optimization_level == OptimizationLevel.CONSERVATIVE:
            self.thresholds = {k: v * 0.8 for k, v in base_thresholds.items()}
        elif self.optimization_level == OptimizationLevel.AGGRESSIVE:
            self.thresholds = {k: v * 1.2 for k, v in base_thresholds.items()}
        elif self.optimization_level == OptimizationLevel.MAXIMUM:
            self.thresholds = {k: v * 1.3 for k, v in base_thresholds.items()}
        else:  # BALANCED
            self.thresholds = base_thresholds

    def _setup_prompts(self):
        """Langchain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •"""
        
        self.gcp_optimization_prompt = PromptTemplate(
            input_variables=["resource_spec", "current_usage", "workload_profile", "constraints"],
            template="""
            GCP e2-small í™˜ê²½ì˜ ìµœì í™” ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

            ë¦¬ì†ŒìŠ¤ ì‚¬ì–‘:
            {resource_spec}

            í˜„ì¬ ì‚¬ìš©ëŸ‰:
            {current_usage}

            ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼:
            {workload_profile}

            ì œì•½ ì¡°ê±´:
            {constraints}

            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µ:
            {{
                "analysis": {{
                    "current_efficiency": 0.75,
                    "bottlenecks": ["ë©”ëª¨ë¦¬ ë¶€ì¡±", "API í˜¸ì¶œ ê³¼ë‹¤"],
                    "optimization_potential": 35.5
                }},
                "recommendations": [
                    {{
                        "category": "resource/cost/performance/scaling",
                        "priority": 1,
                        "title": "ê¶Œì¥ì‚¬í•­ ì œëª©",
                        "description": "ìƒì„¸ ì„¤ëª…",
                        "expected_improvement": {{"cpu": 15.0, "memory": 20.0}},
                        "implementation_steps": ["ë‹¨ê³„1", "ë‹¨ê³„2"],
                        "estimated_effort": "low/medium/high",
                        "cost_impact": "positive/negative/neutral",
                        "gcp_services": ["Compute Engine", "Cloud Monitoring"]
                    }}
                ],
                "scaling_recommendations": {{
                    "current_instance_adequate": true,
                    "recommended_instance": "e2-medium",
                    "scaling_triggers": {{"cpu": 85, "memory": 90}},
                    "cost_analysis": {{"current_monthly": 24.27, "optimized_monthly": 18.50}}
                }}
            }}
            """
        )
        
        self.workload_analysis_prompt = PromptTemplate(
            input_variables=["metrics_data", "time_patterns", "resource_constraints"],
            template="""
            ë‹¤ìŒ ì›Œí¬ë¡œë“œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ GCP í™˜ê²½ ìµœì í™” ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

            ë©”íŠ¸ë¦­ ë°ì´í„°:
            {metrics_data}

            ì‹œê°„ëŒ€ë³„ íŒ¨í„´:
            {time_patterns}

            ë¦¬ì†ŒìŠ¤ ì œì•½ì‚¬í•­:
            {resource_constraints}

            JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
            {{
                "workload_classification": "ai_inference/web_crawling/data_processing",
                "resource_utilization": {{
                    "cpu_efficiency": 0.82,
                    "memory_efficiency": 0.75,
                    "peak_to_average_ratio": 2.1
                }},
                "optimization_opportunities": [
                    {{
                        "area": "memory_management",
                        "current_waste": 25.5,
                        "optimization_method": "ë°°ì¹˜ í¬ê¸° ì¡°ì •",
                        "expected_savings": 20.0
                    }}
                ],
                "recommended_configuration": {{
                    "max_workers": 3,
                    "batch_size": 20,
                    "memory_limit": "3.2GB",
                    "gc_settings": {{"enabled": true, "interval": 300}}
                }}
            }}
            """
        )

    async def analyze_current_environment(self) -> Dict[str, Any]:
        """
        í˜„ì¬ GCP í™˜ê²½ ë¶„ì„
        
        Returns:
            í™˜ê²½ ë¶„ì„ ê²°ê³¼
        """
        logger.info("ğŸ“Š GCP í™˜ê²½ ë¶„ì„ ì‹œì‘")
        
        try:
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
            system_metrics = await self._collect_system_metrics()
            
            # ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼ ìƒì„±
            workload_profile = await self._analyze_workload_profile()
            
            # ë¦¬ì†ŒìŠ¤ ì œì•½ì‚¬í•­ ë¶„ì„
            constraints = await self._analyze_resource_constraints()
            
            # ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„
            cost_analysis = await self._analyze_cost_efficiency()
            
            # ì„±ëŠ¥ ë³‘ëª©ì  ë¶„ì„
            bottlenecks = await self._identify_performance_bottlenecks()
            
            analysis_result = {
                "timestamp": datetime.now().isoformat(),
                "instance_type": self.target_instance.value,
                "resource_specification": asdict(self.current_spec),
                "system_metrics": system_metrics,
                "workload_profile": asdict(workload_profile),
                "resource_constraints": constraints,
                "cost_analysis": cost_analysis,
                "performance_bottlenecks": bottlenecks,
                "optimization_potential": await self._calculate_optimization_potential(
                    system_metrics, workload_profile, constraints
                )
            }
            
            logger.info("âœ… GCP í™˜ê²½ ë¶„ì„ ì™„ë£Œ")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ GCP í™˜ê²½ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def _collect_system_metrics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        # CPU ì •ë³´
        cpu_info = {
            "usage_percent": psutil.cpu_percent(interval=1),
            "count": psutil.cpu_count(),
            "freq": psutil.cpu_freq()._asdict() if psutil.cpu_freq() else None,
            "load_avg": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None
        }
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_info = psutil.virtual_memory()._asdict()
        memory_info['usage_percent'] = memory_info['percent']
        memory_info['available_gb'] = memory_info['available'] / (1024**3)
        memory_info['used_gb'] = memory_info['used'] / (1024**3)
        
        # ë””ìŠ¤í¬ ì •ë³´
        disk_info = psutil.disk_usage('/')._asdict()
        disk_info['usage_percent'] = (disk_info['used'] / disk_info['total']) * 100
        
        # ë„¤íŠ¸ì›Œí¬ ì •ë³´
        network_info = psutil.net_io_counters()._asdict()
        
        # í”„ë¡œì„¸ìŠ¤ ì •ë³´
        process_count = len(psutil.pids())
        
        return {
            "cpu": cpu_info,
            "memory": memory_info,
            "disk": disk_info,
            "network": network_info,
            "process_count": process_count,
            "collection_time": datetime.now().isoformat()
        }

    async def _analyze_workload_profile(self) -> GCPWorkloadProfile:
        """ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼ ë¶„ì„"""
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        if self.performance_monitor:
            # ìµœê·¼ 1ì‹œê°„ ë°ì´í„° ì‚¬ìš©
            metrics_data = []
            for metric in list(self.performance_monitor.metrics_buffer)[-60:]:  # ìµœê·¼ 60ê°œ
                if metric.metric_type == MetricType.SYSTEM_RESOURCE:
                    metrics_data.append(metric)
        else:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ê°€ ì—†ëŠ” ê²½ìš° í˜„ì¬ ê°’ ì‚¬ìš©
            current_metrics = await self._collect_system_metrics()
            metrics_data = [current_metrics]
        
        # ì›Œí¬ë¡œë“œ ë¶„ë¥˜ (AI ì¶”ë¡  ê¸°ë°˜)
        workload_type = "ai_inference"  # ê¸°ë³¸ê°’
        
        # CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë¶„ì„
        if metrics_data:
            if isinstance(metrics_data[0], dict):
                # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ë©”íŠ¸ë¦­
                cpu_values = [m.get('cpu', {}).get('usage_percent', 0) for m in metrics_data]
                memory_values = [m.get('memory', {}).get('usage_percent', 0) for m in metrics_data]
            else:
                # PerformanceMetric ê°ì²´
                cpu_values = [m.value for m in metrics_data if m.metric_name == 'cpu_usage']
                memory_values = [m.value for m in metrics_data if m.metric_name == 'memory_usage']
            
            if cpu_values and memory_values:
                peak_cpu = max(cpu_values)
                peak_memory = max(memory_values)
                avg_cpu = sum(cpu_values) / len(cpu_values)
                avg_memory = sum(memory_values) / len(memory_values)
            else:
                # í˜„ì¬ ê°’ ì‚¬ìš©
                current = await self._collect_system_metrics()
                peak_cpu = avg_cpu = current['cpu']['usage_percent']
                peak_memory = avg_memory = current['memory']['usage_percent']
        else:
            # ê¸°ë³¸ê°’
            current = await self._collect_system_metrics()
            peak_cpu = avg_cpu = current['cpu']['usage_percent']
            peak_memory = avg_memory = current['memory']['usage_percent']
        
        return GCPWorkloadProfile(
            workload_type=workload_type,
            peak_cpu_usage=peak_cpu,
            peak_memory_usage=peak_memory,
            average_cpu_usage=avg_cpu,
            average_memory_usage=avg_memory,
            network_throughput_mbps=10.0,  # ì¶”ì •ê°’
            disk_io_iops=100.0,  # ì¶”ì •ê°’
            api_requests_per_minute=30.0,  # ì¶”ì •ê°’
            burst_capability_required=peak_cpu > avg_cpu * 1.5
        )

    async def _analyze_resource_constraints(self) -> List[ResourceConstraint]:
        """ë¦¬ì†ŒìŠ¤ ì œì•½ì‚¬í•­ ë¶„ì„"""
        constraints = []
        
        current_metrics = await self._collect_system_metrics()
        
        # CPU ì œì•½ í™•ì¸
        cpu_usage = current_metrics['cpu']['usage_percent']
        if cpu_usage > self.thresholds['cpu_warning']:
            constraints.append(ResourceConstraint.CPU_BOUND)
        
        # ë©”ëª¨ë¦¬ ì œì•½ í™•ì¸
        memory_usage = current_metrics['memory']['usage_percent']
        if memory_usage > self.thresholds['memory_warning']:
            constraints.append(ResourceConstraint.MEMORY_BOUND)
        
        # ë””ìŠ¤í¬ ì œì•½ í™•ì¸
        disk_usage = current_metrics['disk']['usage_percent']
        if disk_usage > 80.0:
            constraints.append(ResourceConstraint.DISK_BOUND)
        
        # API ì œì•½ í™•ì¸ (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” Cloud Monitoring APIì—ì„œ í• ë‹¹ëŸ‰ ì •ë³´ ìˆ˜ì§‘
        if hasattr(self, 'api_quota_usage') and self.api_quota_usage > 80.0:
            constraints.append(ResourceConstraint.API_BOUND)
        
        return constraints

    async def _analyze_cost_efficiency(self) -> Dict[str, Any]:
        """ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„"""
        # GCP e2-small ê¸°ë³¸ ë¹„ìš© (us-central1 ê¸°ì¤€)
        base_cost_per_hour = 0.033444  # USD
        hours_per_month = 24 * 30
        monthly_base_cost = base_cost_per_hour * hours_per_month
        
        # ì‹¤ì œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ê¸°ë°˜ ë¹„ìš© íš¨ìœ¨ì„± ê³„ì‚°
        current_metrics = await self._collect_system_metrics()
        
        cpu_utilization = current_metrics['cpu']['usage_percent'] / 100
        memory_utilization = current_metrics['memory']['usage_percent'] / 100
        
        # í‰ê·  ì‚¬ìš©ë¥ 
        avg_utilization = (cpu_utilization + memory_utilization) / 2
        
        # ë¹„ìš© íš¨ìœ¨ì„± ì ìˆ˜ (ì‚¬ìš©ë¥  ê¸°ë°˜)
        efficiency_score = min(avg_utilization / 0.7, 1.0)  # 70% ì‚¬ìš©ë¥ ì„ 100% íš¨ìœ¨ì„±ìœ¼ë¡œ ê°„ì£¼
        
        # ì˜ˆìƒ ì ˆì•½ ê°€ëŠ¥ ë¹„ìš©
        if avg_utilization < 0.3:  # 30% ì´í•˜ ì‚¬ìš© ì‹œ ë‹¤ìš´ê·¸ë ˆì´ë“œ ê¶Œì¥
            potential_savings = monthly_base_cost * 0.4  # e2-microë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ
        elif avg_utilization > 0.9:  # 90% ì´ìƒ ì‚¬ìš© ì‹œ ì—…ê·¸ë ˆì´ë“œ í•„ìš”
            potential_savings = -monthly_base_cost * 0.5  # e2-mediumìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ë¹„ìš©
        else:
            potential_savings = 0
        
        return {
            "current_monthly_cost": monthly_base_cost,
            "efficiency_score": efficiency_score,
            "avg_utilization": avg_utilization,
            "potential_monthly_savings": potential_savings,
            "cost_per_effective_hour": monthly_base_cost / (hours_per_month * avg_utilization) if avg_utilization > 0 else float('inf'),
            "optimization_recommendations": [
                "ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ìµœì í™”ë¥¼ í†µí•œ ë¹„ìš© ì ˆê° ê°€ëŠ¥" if efficiency_score < 0.7 else "í˜„ì¬ ë¹„ìš© íš¨ìœ¨ì„± ì–‘í˜¸"
            ]
        }

    async def _identify_performance_bottlenecks(self) -> List[Dict[str, Any]]:
        """ì„±ëŠ¥ ë³‘ëª©ì  ì‹ë³„"""
        bottlenecks = []
        
        current_metrics = await self._collect_system_metrics()
        
        # CPU ë³‘ëª©
        cpu_usage = current_metrics['cpu']['usage_percent']
        if cpu_usage > self.thresholds['cpu_critical']:
            bottlenecks.append({
                "type": "cpu",
                "severity": "critical",
                "current_value": cpu_usage,
                "threshold": self.thresholds['cpu_critical'],
                "impact": "high",
                "recommendations": [
                    "ë™ì‹œ ì‘ì—… ìˆ˜ ê°ì†Œ",
                    "CPU ì§‘ì•½ì  ì‘ì—… ìµœì í™”",
                    "ì¸ìŠ¤í„´ìŠ¤ ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤"
                ]
            })
        elif cpu_usage > self.thresholds['cpu_warning']:
            bottlenecks.append({
                "type": "cpu",
                "severity": "warning",
                "current_value": cpu_usage,
                "threshold": self.thresholds['cpu_warning'],
                "impact": "medium",
                "recommendations": [
                    "ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ìµœì í™”",
                    "ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬"
                ]
            })
        
        # ë©”ëª¨ë¦¬ ë³‘ëª©
        memory_usage = current_metrics['memory']['usage_percent']
        if memory_usage > self.thresholds['memory_critical']:
            bottlenecks.append({
                "type": "memory",
                "severity": "critical",
                "current_value": memory_usage,
                "threshold": self.thresholds['memory_critical'],
                "impact": "high",
                "recommendations": [
                    "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸",
                    "ë°°ì¹˜ í¬ê¸° ê°ì†Œ",
                    "ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”",
                    "ë©”ëª¨ë¦¬ ì¦ì„¤ ê³ ë ¤"
                ]
            })
        elif memory_usage > self.thresholds['memory_warning']:
            bottlenecks.append({
                "type": "memory",
                "severity": "warning",
                "current_value": memory_usage,
                "threshold": self.thresholds['memory_warning'],
                "impact": "medium",
                "recommendations": [
                    "ë¶ˆí•„ìš”í•œ ìºì‹œ ì •ë¦¬",
                    "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°•í™”"
                ]
            })
        
        # ë””ìŠ¤í¬ I/O ë³‘ëª© (ê°„ì ‘ ì¸¡ì •)
        disk_usage = current_metrics['disk']['usage_percent']
        if disk_usage > 90:
            bottlenecks.append({
                "type": "disk",
                "severity": "warning",
                "current_value": disk_usage,
                "threshold": 90,
                "impact": "medium",
                "recommendations": [
                    "ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬",
                    "ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜",
                    "ë””ìŠ¤í¬ ìš©ëŸ‰ ì¦ì„¤"
                ]
            })
        
        return bottlenecks

    async def _calculate_optimization_potential(
        self,
        system_metrics: Dict[str, Any],
        workload_profile: GCPWorkloadProfile,
        constraints: List[ResourceConstraint]
    ) -> Dict[str, Any]:
        """ìµœì í™” ì ì¬ë ¥ ê³„ì‚°"""
        
        # í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íš¨ìœ¨ì„±
        cpu_efficiency = min(workload_profile.average_cpu_usage / 70.0, 1.0)  # 70%ë¥¼ ìµœì ìœ¼ë¡œ ê°„ì£¼
        memory_efficiency = min(workload_profile.average_memory_usage / 70.0, 1.0)
        
        overall_efficiency = (cpu_efficiency + memory_efficiency) / 2
        
        # ìµœì í™” ì ì¬ë ¥ (1 - íš¨ìœ¨ì„±)
        optimization_potential = (1 - overall_efficiency) * 100
        
        # ì œì•½ì‚¬í•­ë³„ ê°œì„  ê°€ëŠ¥ì„±
        improvement_areas = []
        
        if ResourceConstraint.CPU_BOUND in constraints:
            improvement_areas.append({
                "area": "CPU ìµœì í™”",
                "potential": min(30.0, optimization_potential * 0.4),
                "methods": ["ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”", "ì•Œê³ ë¦¬ì¦˜ ê°œì„ ", "ìºì‹± ì „ëµ"]
            })
        
        if ResourceConstraint.MEMORY_BOUND in constraints:
            improvement_areas.append({
                "area": "ë©”ëª¨ë¦¬ ìµœì í™”",
                "potential": min(35.0, optimization_potential * 0.5),
                "methods": ["ë©”ëª¨ë¦¬ í’€ë§", "ë°°ì¹˜ í¬ê¸° ì¡°ì •", "ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŠœë‹"]
            })
        
        if ResourceConstraint.API_BOUND in constraints:
            improvement_areas.append({
                "area": "API ìµœì í™”",
                "potential": min(25.0, optimization_potential * 0.3),
                "methods": ["ìš”ì²­ ìºì‹±", "ë°°ì¹˜ ì²˜ë¦¬", "API í˜¸ì¶œ ìµœì í™”"]
            })
        
        return {
            "overall_potential_percent": optimization_potential,
            "current_efficiency": overall_efficiency,
            "improvement_areas": improvement_areas,
            "expected_performance_gain": optimization_potential * 0.6,  # ë³´ìˆ˜ì  ì¶”ì •
            "expected_cost_savings": optimization_potential * 0.4,
            "optimization_complexity": "medium" if optimization_potential > 20 else "low"
        }

    async def generate_optimization_recommendations(
        self,
        analysis_result: Optional[Dict[str, Any]] = None
    ) -> List[GCPOptimizationRecommendation]:
        """
        GCP ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
        
        Args:
            analysis_result: í™˜ê²½ ë¶„ì„ ê²°ê³¼ (Noneì¸ ê²½ìš° ìƒˆë¡œ ë¶„ì„)
            
        Returns:
            ìµœì í™” ê¶Œì¥ì‚¬í•­ ëª©ë¡
        """
        logger.info("ğŸ¯ GCP ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹œì‘")
        
        try:
            # ë¶„ì„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë¶„ì„
            if not analysis_result:
                analysis_result = await self.analyze_current_environment()
            
            recommendations = []
            
            # 1. ë¦¬ì†ŒìŠ¤ ìµœì í™” ê¶Œì¥ì‚¬í•­
            resource_recommendations = await self._generate_resource_recommendations(analysis_result)
            recommendations.extend(resource_recommendations)
            
            # 2. ë¹„ìš© ìµœì í™” ê¶Œì¥ì‚¬í•­
            cost_recommendations = await self._generate_cost_recommendations(analysis_result)
            recommendations.extend(cost_recommendations)
            
            # 3. ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­
            performance_recommendations = await self._generate_performance_recommendations(analysis_result)
            recommendations.extend(performance_recommendations)
            
            # 4. ìŠ¤ì¼€ì¼ë§ ê¶Œì¥ì‚¬í•­
            scaling_recommendations = await self._generate_scaling_recommendations(analysis_result)
            recommendations.extend(scaling_recommendations)
            
            # 5. AI ê¸°ë°˜ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
            ai_recommendations = await self._generate_ai_recommendations(analysis_result)
            recommendations.extend(ai_recommendations)
            
            # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
            recommendations.sort(key=lambda x: (x.priority, x.risk_level))
            
            # ê¶Œì¥ì‚¬í•­ ìºì‹œì— ì €ì¥
            for rec in recommendations:
                self.recommendation_cache[rec.id] = rec
            
            logger.info(f"âœ… {len(recommendations)}ê°œì˜ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„± ì™„ë£Œ")
            
            return recommendations
            
        except Exception as e:
            logger.error(f"âŒ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    async def _generate_resource_recommendations(
        self,
        analysis: Dict[str, Any]
    ) -> List[GCPOptimizationRecommendation]:
        """ë¦¬ì†ŒìŠ¤ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        bottlenecks = analysis.get('performance_bottlenecks', [])
        workload = analysis.get('workload_profile', {})
        
        # CPU ìµœì í™”
        for bottleneck in bottlenecks:
            if bottleneck.get('type') == 'cpu' and bottleneck.get('severity') == 'critical':
                recommendations.append(GCPOptimizationRecommendation(
                    id=f"cpu_opt_{int(time.time())}",
                    category="resource",
                    priority=1,
                    title="CPU ì‚¬ìš©ë¥  ìµœì í™”",
                    description=f"í˜„ì¬ CPU ì‚¬ìš©ë¥ ì´ {bottleneck['current_value']:.1f}%ë¡œ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë™ì‹œ ì‘ì—… ìˆ˜ë¥¼ ì¤„ì´ê³  CPU ì§‘ì•½ì  ì‘ì—…ì„ ìµœì í™”í•´ì•¼ í•©ë‹ˆë‹¤.",
                    expected_improvement={"cpu": 25.0, "performance": 20.0},
                    implementation_steps=[
                        "í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ë¶„ì„",
                        "ë™ì‹œ í¬ë¡¤ë§ ì›Œì»¤ ìˆ˜ë¥¼ 2ê°œì—ì„œ 1ê°œë¡œ ê°ì†Œ",
                        "AI ì¶”ë¡  ë°°ì¹˜ í¬ê¸°ë¥¼ 50%ë¡œ ê°ì†Œ",
                        "CPU í”„ë¡œíŒŒì¼ë§ì„ í†µí•œ ë³‘ëª©ì  ì‹ë³„"
                    ],
                    estimated_effort="medium",
                    estimated_time="2-4ì‹œê°„",
                    cost_impact="positive",
                    risk_level="low",
                    gcp_services=["Compute Engine", "Cloud Monitoring"],
                    billing_impact="ë¹„ìš© ì ˆê° ì˜ˆìƒ",
                    monitoring_metrics=["cpu_utilization", "load_average"]
                ))
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        for bottleneck in bottlenecks:
            if bottleneck.get('type') == 'memory':
                severity = bottleneck.get('severity')
                priority = 1 if severity == 'critical' else 2
                
                recommendations.append(GCPOptimizationRecommendation(
                    id=f"memory_opt_{int(time.time())}",
                    category="resource",
                    priority=priority,
                    title="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
                    description=f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {bottleneck['current_value']:.1f}%ì…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ì—¬ ì•ˆì •ì„±ì„ í™•ë³´í•´ì•¼ í•©ë‹ˆë‹¤.",
                    expected_improvement={"memory": 30.0, "stability": 25.0},
                    implementation_steps=[
                        "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ ë° ëˆ„ìˆ˜ íƒì§€",
                        "ë°ì´í„° ë°°ì¹˜ í¬ê¸°ë¥¼ 25ê°œì—ì„œ 15ê°œë¡œ ê°ì†Œ",
                        "ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì„¤ì • ìµœì í™”",
                        "ë¶ˆí•„ìš”í•œ ìºì‹œ ë°ì´í„° ì •ë¦¬",
                        "ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ê°•í™”"
                    ],
                    estimated_effort="medium",
                    estimated_time="3-6ì‹œê°„",
                    cost_impact="positive",
                    risk_level="low",
                    gcp_services=["Compute Engine", "Cloud Monitoring"],
                    monitoring_metrics=["memory_utilization", "memory_usage"]
                ))
        
        return recommendations

    async def _generate_cost_recommendations(
        self,
        analysis: Dict[str, Any]
    ) -> List[GCPOptimizationRecommendation]:
        """ë¹„ìš© ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        cost_analysis = analysis.get('cost_analysis', {})
        efficiency_score = cost_analysis.get('efficiency_score', 0.5)
        potential_savings = cost_analysis.get('potential_monthly_savings', 0)
        
        if efficiency_score < 0.6:
            recommendations.append(GCPOptimizationRecommendation(
                id=f"cost_efficiency_{int(time.time())}",
                category="cost",
                priority=2,
                title="ë¹„ìš© íš¨ìœ¨ì„± ê°œì„ ",
                description=f"í˜„ì¬ ë¹„ìš© íš¨ìœ¨ì„±ì´ {efficiency_score:.1%}ë¡œ ë‚®ìŠµë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì„ ê°œì„ í•˜ì—¬ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                expected_improvement={"cost": abs(potential_savings) / cost_analysis.get('current_monthly_cost', 1) * 100},
                implementation_steps=[
                    "ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íŒ¨í„´ ë¶„ì„",
                    "ìœ íœ´ ì‹œê°„ëŒ€ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ìµœì í™”",
                    "ë¶ˆí•„ìš”í•œ ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬",
                    "ìŠ¤ì¼€ì¤„ ê¸°ë°˜ ìë™ ì¢…ë£Œ ì„¤ì • ê³ ë ¤"
                ],
                estimated_effort="low",
                estimated_time="1-2ì‹œê°„",
                cost_impact="positive",
                risk_level="low",
                gcp_services=["Compute Engine", "Cloud Scheduler"],
                billing_impact=f"ì›” ${abs(potential_savings):.2f} ì ˆê° ì˜ˆìƒ",
                monitoring_metrics=["billing_data", "resource_utilization"]
            ))
        
        # API ë¹„ìš© ìµœì í™”
        workload = analysis.get('workload_profile', {})
        api_rpm = workload.get('api_requests_per_minute', 0)
        
        if api_rpm > 40:  # ë†’ì€ API ì‚¬ìš©ëŸ‰
            recommendations.append(GCPOptimizationRecommendation(
                id=f"api_cost_opt_{int(time.time())}",
                category="cost",
                priority=2,
                title="AI API ë¹„ìš© ìµœì í™”",
                description=f"ë¶„ë‹¹ {api_rpm}íšŒì˜ API í˜¸ì¶œë¡œ ë¹„ìš©ì´ ë†’ìŠµë‹ˆë‹¤. ìºì‹±ê³¼ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•´ API ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                expected_improvement={"cost": 40.0, "api_efficiency": 35.0},
                implementation_steps=[
                    "API ì‘ë‹µ ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„",
                    "ìœ ì‚¬í•œ ìš”ì²­ë“¤ì˜ ë°°ì¹˜ ì²˜ë¦¬",
                    "ì €í’ˆì§ˆ ë°ì´í„°ì— ëŒ€í•œ AI ì²˜ë¦¬ ìƒëµ",
                    "API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°•í™”"
                ],
                estimated_effort="medium",
                estimated_time="4-8ì‹œê°„",
                cost_impact="positive",
                risk_level="low",
                gcp_services=["Vertex AI", "Cloud Functions"],
                billing_impact="API ë¹„ìš© 30-40% ì ˆê° ì˜ˆìƒ",
                monitoring_metrics=["api_request_count", "api_cost"]
            ))
        
        return recommendations

    async def _generate_performance_recommendations(
        self,
        analysis: Dict[str, Any]
    ) -> List[GCPOptimizationRecommendation]:
        """ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        workload = analysis.get('workload_profile', {})
        optimization_potential = analysis.get('optimization_potential', {})
        
        # ë„¤íŠ¸ì›Œí¬ ìµœì í™”
        if workload.get('network_throughput_mbps', 0) > 8:  # e2-small ë„¤íŠ¸ì›Œí¬ ì œí•œ ê³ ë ¤
            recommendations.append(GCPOptimizationRecommendation(
                id=f"network_opt_{int(time.time())}",
                category="performance",
                priority=3,
                title="ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬ëŸ‰ ìµœì í™”",
                description="ë†’ì€ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ì¸í•œ ë³‘ëª© ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì—°ê²° í’€ë§ê³¼ ì••ì¶•ì„ í†µí•´ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                expected_improvement={"network": 25.0, "latency": 20.0},
                implementation_steps=[
                    "HTTP ì—°ê²° í’€ë§ êµ¬í˜„",
                    "ì‘ë‹µ ë°ì´í„° ì••ì¶• í™œì„±í™”",
                    "ë¶ˆí•„ìš”í•œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì œê±°",
                    "CDN ì‚¬ìš© ê³ ë ¤ (ì •ì  ë¦¬ì†ŒìŠ¤)"
                ],
                estimated_effort="medium",
                estimated_time="3-5ì‹œê°„",
                cost_impact="neutral",
                risk_level="low",
                gcp_services=["Compute Engine", "Cloud CDN"],
                monitoring_metrics=["network_throughput", "latency"]
            ))
        
        # ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ë§ ìµœì í™”
        if workload.get('burst_capability_required', False):
            recommendations.append(GCPOptimizationRecommendation(
                id=f"scheduling_opt_{int(time.time())}",
                category="performance",
                priority=2,
                title="ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ë§ ìµœì í™”",
                description="ë²„ìŠ¤íŠ¸ ì‘ì—…ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ì—… ìŠ¤ì¼€ì¤„ë§ì„ ìµœì í™”í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ì„ í‰ì¤€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                expected_improvement={"performance": 30.0, "stability": 25.0},
                implementation_steps=[
                    "í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„",
                    "ì‘ì—… í ì‹œìŠ¤í…œ êµ¬í˜„",
                    "ì ì§„ì  ì‘ì—… ì²˜ë¦¬ (ìŠ¤ë¡œí‹€ë§)",
                    "ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìš°ì„ ìˆœìœ„ ì¡°ì •"
                ],
                estimated_effort="high",
                estimated_time="1-2ì¼",
                cost_impact="positive",
                risk_level="medium",
                gcp_services=["Cloud Tasks", "Cloud Scheduler"],
                monitoring_metrics=["queue_depth", "processing_time"]
            ))
        
        return recommendations

    async def _generate_scaling_recommendations(
        self,
        analysis: Dict[str, Any]
    ) -> List[GCPOptimizationRecommendation]:
        """ìŠ¤ì¼€ì¼ë§ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        workload = analysis.get('workload_profile', {})
        cost_analysis = analysis.get('cost_analysis', {})
        
        avg_cpu = workload.get('average_cpu_usage', 0)
        avg_memory = workload.get('average_memory_usage', 0)
        peak_cpu = workload.get('peak_cpu_usage', 0)
        peak_memory = workload.get('peak_memory_usage', 0)
        
        # ë‹¤ìš´ê·¸ë ˆì´ë“œ ê¶Œì¥ (ì €ì‚¬ìš©ë¥ )
        if avg_cpu < 30 and avg_memory < 40:
            recommendations.append(GCPOptimizationRecommendation(
                id=f"downgrade_{int(time.time())}",
                category="scaling",
                priority=3,
                title="ì¸ìŠ¤í„´ìŠ¤ ë‹¤ìš´ê·¸ë ˆì´ë“œ ê³ ë ¤",
                description=f"í‰ê·  ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ (CPU: {avg_cpu:.1f}%, Memory: {avg_memory:.1f}%). e2-microë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œí•˜ì—¬ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                expected_improvement={"cost": 50.0},
                implementation_steps=[
                    "e2-micro í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰",
                    "ì„±ëŠ¥ ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§",
                    "ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš",
                    "ë¡¤ë°± ê³„íš ìˆ˜ë¦½"
                ],
                estimated_effort="high",
                estimated_time="1-2ì¼",
                cost_impact="positive",
                risk_level="medium",
                gcp_services=["Compute Engine"],
                billing_impact="ì›” $12-15 ì ˆê° ì˜ˆìƒ",
                monitoring_metrics=["instance_performance", "cost_metrics"]
            ))
        
        # ì—…ê·¸ë ˆì´ë“œ ê¶Œì¥ (ê³ ì‚¬ìš©ë¥ )
        elif peak_cpu > 85 or peak_memory > 85:
            next_instance = "e2-medium" if self.target_instance == GCPInstanceType.E2_SMALL else "e2-standard-2"
            
            recommendations.append(GCPOptimizationRecommendation(
                id=f"upgrade_{int(time.time())}",
                category="scaling",
                priority=1,
                title=f"{next_instance}ë¡œ ì—…ê·¸ë ˆì´ë“œ ê¶Œì¥",
                description=f"í”¼í¬ ì‹œê°„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ (CPU: {peak_cpu:.1f}%, Memory: {peak_memory:.1f}%). ì•ˆì •ì„± í™•ë³´ë¥¼ ìœ„í•´ ì—…ê·¸ë ˆì´ë“œë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.",
                expected_improvement={"performance": 40.0, "stability": 50.0},
                implementation_steps=[
                    "ì—…ê·¸ë ˆì´ë“œ ì‹œì  ê³„íš",
                    "ë°ì´í„° ë°±ì—… ìˆ˜í–‰",
                    "ì¸ìŠ¤í„´ìŠ¤ í¬ê¸° ë³€ê²½",
                    "ì„±ëŠ¥ ê²€ì¦ ë° ëª¨ë‹ˆí„°ë§"
                ],
                estimated_effort="medium",
                estimated_time="2-4ì‹œê°„",
                cost_impact="negative",
                risk_level="low",
                gcp_services=["Compute Engine"],
                billing_impact=f"ì›” ${24.27 * 0.5:.2f} ë¹„ìš© ì¦ê°€ ì˜ˆìƒ",
                monitoring_metrics=["instance_performance", "resource_utilization"]
            ))
        
        return recommendations

    async def _generate_ai_recommendations(
        self,
        analysis: Dict[str, Any]
    ) -> List[GCPOptimizationRecommendation]:
        """AI ê¸°ë°˜ ê³ ê¸‰ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        try:
            # AI ì²´ì¸ì„ ì‚¬ìš©í•œ ì¢…í•© ë¶„ì„
            chain = LLMChain(
                llm=self.gemini_client.get_llm(),
                prompt=self.gcp_optimization_prompt
            )
            
            # ë¶„ì„ ë°ì´í„° ì¤€ë¹„
            resource_spec = json.dumps(asdict(self.current_spec))
            current_usage = json.dumps(analysis.get('system_metrics', {}))
            workload_profile = json.dumps(analysis.get('workload_profile', {}))
            constraints = json.dumps([c.value for c in analysis.get('resource_constraints', [])])
            
            # AI ë¶„ì„ ì‹¤í–‰
            response = await chain.arun(
                resource_spec=resource_spec,
                current_usage=current_usage,
                workload_profile=workload_profile,
                constraints=constraints
            )
            
            # JSON ì‘ë‹µ íŒŒì‹±
            ai_analysis = json.loads(response.strip())
            
            # AI ê¶Œì¥ì‚¬í•­ì„ GCPOptimizationRecommendation ê°ì²´ë¡œ ë³€í™˜
            ai_recommendations = []
            
            for rec_data in ai_analysis.get('recommendations', []):
                recommendation = GCPOptimizationRecommendation(
                    id=f"ai_rec_{int(time.time())}_{len(ai_recommendations)}",
                    category=rec_data.get('category', 'performance'),
                    priority=rec_data.get('priority', 3),
                    title=rec_data.get('title', 'AI ê¶Œì¥ì‚¬í•­'),
                    description=rec_data.get('description', ''),
                    expected_improvement=rec_data.get('expected_improvement', {}),
                    implementation_steps=rec_data.get('implementation_steps', []),
                    estimated_effort=rec_data.get('estimated_effort', 'medium'),
                    estimated_time="AI ë¶„ì„ ê¸°ë°˜",
                    cost_impact=rec_data.get('cost_impact', 'neutral'),
                    risk_level="low",
                    gcp_services=rec_data.get('gcp_services', []),
                    billing_impact="AI ë¶„ì„ ê¸°ë°˜ ì˜ˆì¸¡",
                    monitoring_metrics=["ai_recommendation_metrics"]
                )
                ai_recommendations.append(recommendation)
            
            return ai_recommendations
            
        except Exception as e:
            logger.warning(f"âš ï¸ AI ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    async def apply_optimization(
        self,
        recommendation_id: str,
        dry_run: bool = True
    ) -> Dict[str, Any]:
        """
        ìµœì í™” ê¶Œì¥ì‚¬í•­ ì ìš©
        
        Args:
            recommendation_id: ì ìš©í•  ê¶Œì¥ì‚¬í•­ ID
            dry_run: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì—¬ë¶€
            
        Returns:
            ì ìš© ê²°ê³¼
        """
        logger.info(f"ğŸš€ ìµœì í™” ì ìš© ì‹œì‘: {recommendation_id} (dry_run: {dry_run})")
        
        if recommendation_id not in self.recommendation_cache:
            return {"error": "ê¶Œì¥ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        recommendation = self.recommendation_cache[recommendation_id]
        
        try:
            # ì‚¬ì „ ê²€ì¦
            validation_result = await self._validate_optimization(recommendation)
            if not validation_result['valid']:
                return {"error": f"ê²€ì¦ ì‹¤íŒ¨: {validation_result['reason']}"}
            
            # ì ìš© ì „ ìƒíƒœ ë°±ì—…
            pre_state = await self._capture_system_state()
            
            if dry_run:
                # ë“œë¼ì´ ëŸ° ì‹œë®¬ë ˆì´ì…˜
                simulation_result = await self._simulate_optimization(recommendation)
                return {
                    "status": "dry_run_completed",
                    "recommendation": asdict(recommendation),
                    "validation": validation_result,
                    "simulation": simulation_result,
                    "pre_state": pre_state
                }
            else:
                # ì‹¤ì œ ì ìš©
                application_result = await self._apply_optimization_real(recommendation)
                
                # ì ìš© í›„ ìƒíƒœ í™•ì¸
                post_state = await self._capture_system_state()
                
                # ê²°ê³¼ ê¸°ë¡
                self.optimization_history.append({
                    "timestamp": datetime.now().isoformat(),
                    "recommendation_id": recommendation_id,
                    "recommendation": asdict(recommendation),
                    "pre_state": pre_state,
                    "post_state": post_state,
                    "result": application_result
                })
                
                return {
                    "status": "applied",
                    "recommendation": asdict(recommendation),
                    "pre_state": pre_state,
                    "post_state": post_state,
                    "application_result": application_result
                }
            
        except Exception as e:
            logger.error(f"âŒ ìµœì í™” ì ìš© ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def _validate_optimization(
        self,
        recommendation: GCPOptimizationRecommendation
    ) -> Dict[str, Any]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ê²€ì¦"""
        
        # ê¸°ë³¸ ê²€ì¦
        if recommendation.risk_level == "high":
            return {
                "valid": False,
                "reason": "ê³ ìœ„í—˜ ê¶Œì¥ì‚¬í•­ì€ ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }
        
        # ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„± í™•ì¸
        current_metrics = await self._collect_system_metrics()
        
        if recommendation.category == "scaling":
            # ìŠ¤ì¼€ì¼ë§ ê¶Œì¥ì‚¬í•­ì˜ ê²½ìš° í˜„ì¬ ì‚¬ìš©ë¥  í™•ì¸
            cpu_usage = current_metrics['cpu']['usage_percent']
            memory_usage = current_metrics['memory']['usage_percent']
            
            if "ì—…ê·¸ë ˆì´ë“œ" in recommendation.title and (cpu_usage < 50 or memory_usage < 50):
                return {
                    "valid": False,
                    "reason": "í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì´ ë‚®ì•„ ì—…ê·¸ë ˆì´ë“œê°€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤"
                }
        
        return {"valid": True, "reason": "ê²€ì¦ í†µê³¼"}

    async def _capture_system_state(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ìº¡ì²˜"""
        return {
            "timestamp": datetime.now().isoformat(),
            "metrics": await self._collect_system_metrics(),
            "processes": len(psutil.pids()),
            "instance_type": self.target_instance.value
        }

    async def _simulate_optimization(
        self,
        recommendation: GCPOptimizationRecommendation
    ) -> Dict[str, Any]:
        """ìµœì í™” ì‹œë®¬ë ˆì´ì…˜"""
        
        simulation_result = {
            "simulated_improvements": recommendation.expected_improvement,
            "estimated_risks": [],
            "resource_impact": {},
            "recommendations": [
                "ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ì‹ ì¤‘íˆ ê²€í† í•˜ì„¸ìš”",
                "ì‹¤ì œ ì ìš© ì „ ë°±ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”",
                "ì ì§„ì  ì ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”"
            ]
        }
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì‹œë®¬ë ˆì´ì…˜
        if recommendation.category == "resource":
            simulation_result["resource_impact"] = {
                "cpu_reduction": recommendation.expected_improvement.get("cpu", 0),
                "memory_reduction": recommendation.expected_improvement.get("memory", 0)
            }
        
        elif recommendation.category == "cost":
            cost_savings = recommendation.expected_improvement.get("cost", 0)
            simulation_result["cost_impact"] = {
                "monthly_savings": f"${cost_savings * 0.24:.2f}",  # ì¶”ì • ê³„ì‚°
                "annual_savings": f"${cost_savings * 0.24 * 12:.2f}"
            }
        
        return simulation_result

    async def _apply_optimization_real(
        self,
        recommendation: GCPOptimizationRecommendation
    ) -> Dict[str, Any]:
        """ì‹¤ì œ ìµœì í™” ì ìš© (ì‹œë®¬ë ˆì´ì…˜)"""
        
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” GCP APIë¥¼ í†µí•œ ë¦¬ì†ŒìŠ¤ ë³€ê²½ì„ ìˆ˜í–‰
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì²˜ë¦¬
        
        logger.info(f"ğŸ”§ ìµœì í™” ì ìš© ì¤‘: {recommendation.title}")
        
        # ì ìš© ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(2)  # ì ìš© ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
        
        return {
            "status": "completed",
            "applied_steps": recommendation.implementation_steps,
            "duration": "2ì´ˆ (ì‹œë®¬ë ˆì´ì…˜)",
            "success": True,
            "message": f"{recommendation.title} ì ìš© ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)"
        }

    def get_optimization_history(self) -> List[Dict[str, Any]]:
        """ìµœì í™” ì´ë ¥ ë°˜í™˜"""
        return list(self.optimization_history)

    def get_current_recommendations(self) -> List[GCPOptimizationRecommendation]:
        """í˜„ì¬ ê¶Œì¥ì‚¬í•­ ëª©ë¡ ë°˜í™˜"""
        return list(self.recommendation_cache.values())

    async def generate_optimization_report(self) -> Dict[str, Any]:
        """
        ì¢…í•© ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±
        
        Returns:
            ì¢…í•© ìµœì í™” ë¦¬í¬íŠ¸
        """
        logger.info("ğŸ“Š GCP ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        try:
            # í™˜ê²½ ë¶„ì„
            analysis = await self.analyze_current_environment()
            
            # ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = await self.generate_optimization_recommendations(analysis)
            
            # ë¦¬í¬íŠ¸ êµ¬ì„±
            report = {
                "report_metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "target_instance": self.target_instance.value,
                    "optimization_level": self.optimization_level.value,
                    "analysis_version": "1.0.0"
                },
                "executive_summary": {
                    "current_efficiency": analysis.get('optimization_potential', {}).get('current_efficiency', 0.5),
                    "optimization_potential": analysis.get('optimization_potential', {}).get('overall_potential_percent', 0),
                    "total_recommendations": len(recommendations),
                    "high_priority_recommendations": len([r for r in recommendations if r.priority <= 2]),
                    "estimated_cost_savings": analysis.get('cost_analysis', {}).get('potential_monthly_savings', 0)
                },
                "current_state_analysis": analysis,
                "optimization_recommendations": [asdict(rec) for rec in recommendations],
                "implementation_roadmap": self._create_implementation_roadmap(recommendations),
                "monitoring_recommendations": self._generate_monitoring_recommendations(),
                "optimization_history": self.get_optimization_history()
            }
            
            logger.info("âœ… GCP ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
            return report
            
        except Exception as e:
            logger.error(f"âŒ ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def _create_implementation_roadmap(
        self,
        recommendations: List[GCPOptimizationRecommendation]
    ) -> Dict[str, Any]:
        """êµ¬í˜„ ë¡œë“œë§µ ìƒì„±"""
        
        # ìš°ì„ ìˆœìœ„ë³„ ê·¸ë£¹í™”
        high_priority = [r for r in recommendations if r.priority <= 2]
        medium_priority = [r for r in recommendations if r.priority == 3]
        low_priority = [r for r in recommendations if r.priority >= 4]
        
        return {
            "phase_1_immediate": {
                "duration": "1-2ì£¼",
                "recommendations": [r.title for r in high_priority],
                "expected_impact": "ë†’ì€ ì„±ëŠ¥ ë° ë¹„ìš© ê°œì„ "
            },
            "phase_2_medium_term": {
                "duration": "1-2ê°œì›”",
                "recommendations": [r.title for r in medium_priority],
                "expected_impact": "ì•ˆì •ì„± ë° íš¨ìœ¨ì„± ê°œì„ "
            },
            "phase_3_long_term": {
                "duration": "2-6ê°œì›”",
                "recommendations": [r.title for r in low_priority],
                "expected_impact": "ì¥ê¸°ì  ìµœì í™” ë° ë¹„ìš© ì ˆê°"
            }
        }

    def _generate_monitoring_recommendations(self) -> List[str]:
        """ëª¨ë‹ˆí„°ë§ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        return [
            "Cloud Monitoringì„ í†µí•œ ì‹¤ì‹œê°„ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì„¤ì •",
            "ë¹„ìš© ì•Œë¦¼ ì„¤ì • (ì›” ì˜ˆì‚° ì´ˆê³¼ ì‹œ ì•Œë¦¼)",
            "ì„±ëŠ¥ ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§ (CPU 80%, ë©”ëª¨ë¦¬ 85%)",
            "API ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ë¹„ìš© ëª¨ë‹ˆí„°ë§",
            "ì£¼ê°„ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìë™ ìƒì„± ì„¤ì •",
            "ìŠ¤ì¼€ì¼ë§ íŠ¸ë¦¬ê±° ì¡°ê±´ ëª¨ë‹ˆí„°ë§"
        ] 